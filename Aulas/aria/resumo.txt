https://aria.ci.ufpb.br/ia-para-todos-material/

AULA 01: https://www.youtube.com/watch?v=areBEw5-nrc&list=PLM8TXdmR4D2NfGVIZxXQMkhzmi3uWpA3P&index=1

-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*

AULA 02: https://www.youtube.com/watch?v=jd7U7x6Z_iQ&list=PLM8TXdmR4D2NfGVIZxXQMkhzmi3uWpA3P&index=2
* Aprendizagem supervisionada:
	Modelos preditivos -> Calssificação e Regressão

* Aprendizagem não supervisionada

* Aprendizagem semi-supervisionada

* Aprendizagem por reforço

* Biblioteca para reconhecimento de imagem: LIME

-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*

AULA 03: https://www.youtube.com/watch?v=0xw98dvCUzI&list=PLM8TXdmR4D2NfGVIZxXQMkhzmi3uWpA3P&index=3
* pré-processamento: 
	-eliminar atributos irrelevantes, correlacionados, outliers, duplicados
	-reduzir dimensionalidade
	-ferramentas: boxplot, variancia, desvio padrão, média, mediana, covariância, correlação
	-transformar dados qualitativos em quantitativos, e vice e versa.
	-normalização: quando o limite superior ou inferior de atributos diferentes estão muito diferentes, 
		       ou estão em escalas diferentes, dando mais relevância para algumas variáveis.
	-tipos de normalização: reescala e padronização (melhor para outliers) 

-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*
AULA 04: https://www.youtube.com/watch?v=XzGrwHa3wGg&list=PLM8TXdmR4D2NfGVIZxXQMkhzmi3uWpA3P&index=4&t=226s
* Aprendizagem supervisionada:
	-Support vector machine: Quais amostras A se parecem mais com B, quais B se parecem mais com A, mas eu ainda tenho certeza doque elas são
	-Naive Bayes: Assume que as variáveis são independentes. Assume uma classe com base na probabilidade de cada variável
	-RNA: que parte do cérebro fica mais ativada quando recebe amostras de determinada classe.
	-Learning vector quantization: Cada classe elege uma amostra representante, e essa amostra decide a classe de cada amostra.
	-Random florest: Para um elevado número de amostras, essas amostras são divididas, e para cada divisão é usado uma árvore de decisão.
	-Gradient/Ada boosting: usa árvore de decisões, e para as amostras com erro na classificação, é usada outra árvore de decisões.
* Escolha das variáveis:
	-Escolher variável que resulta em mais puzera para decidir a classe
	-Não usar variáveis que pertencem a todas as classes
	-Ajustar o melhor ponto de corte para as classes (relacionada à variável de saida)
	-usar árvores de decisões (classe 'DecissionTreeClassifier' da biblioteca sklearn.tree) para decidir quais variáveis são mais relevantes
	- cuidar com over fiting

-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*

AULA 05: https://www.youtube.com/watch?v=FY9pxsnlch0&list=PLM8TXdmR4D2NfGVIZxXQMkhzmi3uWpA3P&index=5
* modelos de treinamento:
	- k-medias: usa a distância euclidiana para achar uma média entre as classes
	- Grupo hierarquico:
		- Aglomerativo.
		- Divisivo
* análise das variáveis:
	-análise de componentes principais (PCA): consegue rotacionar os eixos das classes, diminuindo o n° de dimensões de entrada (from sklearn.decomposition import PCA).

-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*
AULA 06: https://www.youtube.com/watch?v=sq28e_xZkZA&list=PLM8TXdmR4D2NfGVIZxXQMkhzmi3uWpA3P&index=6&t=4s
	
* Avaliação de modelos supervisionados por Classificação;
	- Avaliação de classificadores binários: usado quando tem apenas duas classes.
		-Matriz de confusão ou matriz de contigencia; medida de acurácia, recall ( ou cobertura, revocação ou senssibilidades), precissão
	-Under fiting: a matriz confusão mostra desempenho ruim com as amostras de treinamento e de teste
	- Over fitting: a matriz confusão mostra desempenho excelente com as amostras de treinamento e muito ruim com as de teste.
	- froneira de decisão: é possivel ajustar a fronteira de decisão para diminuir os falsos positivos, ou falsos negativos.
* Avaliação de modelos supervisionados por Regressão;
	- Erro quadrático médio e erro absoluto médio; mede a distância das amostras em relação à predição calculada. 
	-validação dos modelos

- Validação cruzada: dividir as amostras em várias partes, e usar subconjuntos diferentes para validação (from sklearn.model_selection import KFold). 
- Validação cruzada extratificada: garante que as amostras de teste e treino tenham a mesma proporção de cada classe (from sklearn.model_selection import StratifieldKFold).

-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*
AULA 07: https://www.youtube.com/watch?v=PdsSlSK2OJ0&list=PLM8TXdmR4D2NfGVIZxXQMkhzmi3uWpA3P&index=7&t=5s
* RNA:
	- Perceptron: imita o neurônio. 
		-Camada simples: Sempre gera uma fronteira de classes linear.
		-Multi camadas:
		-Bibliotecas: TensorFlow, PyTorch
playground.tensorflow.org

-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*
AULA 08: https://www.youtube.com/watch?v=9KQOzpM8vIM&list=PLM8TXdmR4D2NfGVIZxXQMkhzmi3uWpA3P&index=8&t=48s
*RNA convulocional:Usada para tratamento de imagens.
	-Detectar regiões na imagem e fornecer os pixels apenas dessa região para a rna (detectar aresta, canto, borda...), reduzindo a quantidade de neurônios.
	-Aplicar pooling, diminui a matriz pela metada
técnica FGG: https://towardsdatascience.com/feature-visualization-on-convolutional-neural-networks-keras-5561a116d1af
